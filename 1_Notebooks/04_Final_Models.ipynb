{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37a8420",
   "metadata": {},
   "source": [
    "# Final Models and Feature Importance Analysis\n",
    "\n",
    "## Objective\n",
    "Present final regression model performance, feature importance analysis, and comprehensive summary of findings.\n",
    "\n",
    "## CRISP-DM Stage\n",
    "Evaluation and Deployment\n",
    "\n",
    "## Contents\n",
    "- Feature importance visualisation\n",
    "- Final model comparison summary\n",
    "- Cluster interpretation summary\n",
    "- Key insights and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('All libraries imported successfully')\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d948642",
   "metadata": {},
   "source": [
    "## Section 1: Load Models and Results\n",
    "\n",
    "Load the trained models and comparison results from previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 80)\n",
    "print('LOADING MODELS AND RESULTS')\n",
    "print('=' * 80)\n",
    "\n",
    "best_rf_model = pickle.load(open('../2_Outputs/best_regression_model.pkl', 'rb'))\n",
    "comparison_df = pd.read_csv('../model_comparison_results.csv')\n",
    "df_encoded = pd.read_pickle('../2_Outputs/df_encoded_full.pkl')\n",
    "features = pd.read_pickle('../2_Outputs/features_prepared.pkl')\n",
    "\n",
    "print('\\nModels and data loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd38d7",
   "metadata": {},
   "source": [
    "## Section 2: Feature Importance Analysis\n",
    "\n",
    "Display and visualise the most important features from the best regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58977a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 80)\n",
    "print('FEATURE IMPORTANCE ANALYSIS')\n",
    "print('=' * 80)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features.columns,\n",
    "    'importance': best_rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "top_features = feature_importance.tail(20)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(top_features)), top_features['importance'].values, color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'].values)\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 20 Most Important Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop 15 Most Important Features:')\n",
    "print('-' * 50)\n",
    "for idx, (_, row) in enumerate(feature_importance.tail(15).iloc[::-1].iterrows(), 1):\n",
    "    print(f'{idx:2d}. {row[\"feature\"]:40s} -> {row[\"importance\"]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fef4a",
   "metadata": {},
   "source": [
    "## Section 3: Model Performance Summary\n",
    "\n",
    "Review and visualise the regression model comparison results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571b3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 80)\n",
    "print('MODEL PERFORMANCE SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "print('\\n' + comparison_df.to_string(index=False))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "comparison_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], legend=False, color='steelblue')\n",
    "axes[0].set_title('RMSE Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "comparison_df.plot(x='Model', y='MAE', kind='bar', ax=axes[1], legend=False, color='coral')\n",
    "axes[1].set_title('MAE Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "comparison_df.plot(x='Model', y='R2', kind='bar', ax=axes[2], legend=False, color='seagreen')\n",
    "axes[2].set_title('R2 Comparison', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('R2')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_r2 = comparison_df.iloc[0]['R2']\n",
    "\n",
    "print(f'\\nBest Model: {best_model_name}')\n",
    "print(f'Test R2 Score: {best_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37fcb3",
   "metadata": {},
   "source": [
    "## Section 4: Executive Summary\n",
    "\n",
    "Comprehensive summary of analysis findings and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ade23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 80)\n",
    "print('EXECUTIVE SUMMARY')\n",
    "print('=' * 80)\n",
    "\n",
    "summary_text = \"\"\"\n",
    "OPEN UNIVERSITY LEARNING ANALYTICS - ANALYSIS SUMMARY\n",
    "================================================================================\n",
    "\n",
    "1. PROJECT SCOPE\n",
    "   - Analysis of Open University student interaction data\n",
    "   - CRISP-DM methodology applied across all phases\n",
    "   - Objective: Identify at-risk students and segment learning personas\n",
    "\n",
    "2. DATA PREPARATION\n",
    "   - Seven datasets merged using composite keys (id_student, code_module, \n",
    "     code_presentation)\n",
    "   - 50+ features engineered from raw data\n",
    "   - Cold Start Problem addressed (filling NaNs with 0 for inactive students)\n",
    "   - Memory optimisation applied (int32, float32 data types)\n",
    "\n",
    "3. SUPERVISED LEARNING RESULTS (Score Prediction)\n",
    "   - Four regression models compared:\n",
    "     * Linear Regression (baseline)\n",
    "     * Random Forest Regressor (initial)\n",
    "     * XGBoost Regressor\n",
    "     * Random Forest Regressor (hyperparameter tuned)\n",
    "   \n",
    "   - Best Model Performance:\n",
    "\"\"\" + f\"     Model: {best_model_name}\\n\" + f\"     R2 Score: {best_r2:.4f}\\n\" + f\"     RMSE: {comparison_df.iloc[0]['RMSE']:.4f}\\n\" + f\"     MAE: {comparison_df.iloc[0]['MAE']:.4f}\\n\\n\"\n",
    "\n",
    "summary_text += \"\"\"   - Key Feature Drivers:\n",
    "     * VLE engagement metrics (total clicks, clicks per week)\n",
    "     * Assessment submission behaviour\n",
    "     * Student demographics and background\n",
    "\n",
    "4. UNSUPERVISED LEARNING RESULTS (Student Segmentation)\n",
    "   - K-Means clustering identified distinct learning personas\n",
    "   - Optimal cluster number determined using Elbow Method and \n",
    "     Silhouette Score analysis\n",
    "   - Students segmented by:\n",
    "     * Engagement levels (VLE interaction)\n",
    "     * Performance (assessment scores)\n",
    "     * Timeliness (submission patterns)\n",
    "\n",
    "5. KEY INSIGHTS\n",
    "   - Student engagement strongly correlates with academic performance\n",
    "   - Early submission patterns indicate higher success rates\n",
    "   - Consistent VLE participation is critical for success\n",
    "   - Clear student personas enable targeted interventions\n",
    "\n",
    "6. RECOMMENDATIONS\n",
    "   - Deploy regression model for early warning system\n",
    "   - Use cluster assignments for personalised support strategies\n",
    "   - Monitor engagement metrics weekly\n",
    "   - Implement targeted interventions for at-risk clusters\n",
    "   - Match high-performing students with struggling peers (mentoring)\n",
    "\n",
    "7. TECHNICAL ACHIEVEMENTS\n",
    "   - Robust pipeline handling 1M+ records\n",
    "   - Cross-validation and hyperparameter tuning implemented\n",
    "   - Multiple evaluation metrics used\n",
    "   - Reproducible code with fixed random states\n",
    "   - Professional documentation and code organisation\n",
    "\n",
    "================================================================================\n",
    "Analysis completed successfully.\n",
    "All models, results, and visualisations available in preceding notebooks.\n",
    "\"\"\"\n",
    "\n",
    "print(summary_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
