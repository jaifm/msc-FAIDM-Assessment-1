{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Association Rule Mining - Dropout Prediction\n",
                "\n",
                "## Objective\n",
                "Discover **behavioral patterns** that predict student dropout/failure using the **Apriori algorithm**.\n",
                "\n",
                "## Methodology\n",
                "1. **Feature Selection**: Use **36** carefully selected features (Demographics + Behavioral) that are observable *during* the course.\n",
                "2. **Exclusion**: Strict removal of **temporal leakage** (e.g., final scores) and unhelpful features (registration date).\n",
                "3. **Algorithm**: Run Apriori on the **FULL dataset** to find frequent itemsets.\n",
                "4. **Refinement**: \n",
                "   - **Deduplication**: Remove redundant variations of the same rule.\n",
                "   - **Diversity Filtering**: Select distinct patterns with different feature combinations.\n",
                "5. **Interpretation**: Translate technical rules into **Plain English** for educational interventions.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from mlxtend.frequent_patterns import apriori, association_rules\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('‚úì Libraries imported')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data (Full Dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load encoded data\n",
                "df_encoded = pd.read_pickle('../2_Outputs/df_encoded_full.pkl')\n",
                "\n",
                "print(f'‚úì Data loaded: {df_encoded.shape}')\n",
                "print(f'  Students: {len(df_encoded):,}')\n",
                "print(f'  Total features: {len(df_encoded.columns)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Selection (Prevention of Leakage)\n",
                "\n",
                "We rigorously exclude features that would cause **temporal leakage** (knowing the future):\n",
                "- ‚ùå **Score Aggregates** (`score_mean`, `score_max`, etc.) - calculated at end of course\n",
                "- ‚ùå **Total Counts** (`total_clicks`, `days_active`) - require full course duration\n",
                "- ‚ùå **Course Structure** (`studied_credits`, `num_assessments`) - static, not behavioral\n",
                "- ‚ùå **Registration Date** - not predictive enough on its own"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EXPLICIT exclusions\n",
                "exclude = [\n",
                "    'id_student', 'code_module', 'code_presentation',\n",
                "    'final_result',  # Target - will add back later\n",
                "    'target_score',  # Leakage\n",
                "    # Course structure - unhelpful\n",
                "    'studied_credits', 'course_weeks', 'num_assessments',\n",
                "    # Temporal features - leakage or unhelpful\n",
                "    'date_registration', 'days_active', 'date_max', 'date_min'\n",
                "]\n",
                "\n",
                "# PATTERN exclusions (Leakage)\n",
                "exclude_patterns = [\n",
                "    'total_', 'avg_', 'mean_', 'final_', 'overall_', \n",
                "    'score_mean', 'score_max', 'score_min', 'score_std', 'weighted_avg'\n",
                "]\n",
                "\n",
                "# Select Valid Features\n",
                "early_features = []\n",
                "for col in df_encoded.columns:\n",
                "    if col in exclude:\n",
                "        continue\n",
                "    if any(pattern in col.lower() for pattern in exclude_patterns):\n",
                "        continue\n",
                "    early_features.append(col)\n",
                "\n",
                "# Add target back\n",
                "early_features.append('final_result')\n",
                "\n",
                "print(f'‚úì Selected {len(early_features)} valid features')\n",
                "print(f'  (Excluded {len(df_encoded.columns) - len(early_features)} features)')\n",
                "\n",
                "print('\\nFeature Categories:')\n",
                "print(f\"- Demographics: {len([c for c in early_features if any(x in c for x in ['gender', 'age', 'region', 'imd', 'education', 'disability'])])} features\")\n",
                "print(f\"- Behavioral:   {len([c for c in early_features if any(x in c for x in ['click', 'delay', 'late'])])} features\")\n",
                "print(f\"- Target:       1 feature\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Transformation (Binning)\n",
                "Association rules require categorical/boolean data. We bin numeric features into meaningful groups."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_basket = df_encoded[early_features].copy()\n",
                "\n",
                "numeric_cols = [c for c in early_features if c != 'final_result' \n",
                "                and df_basket[c].dtype in ['float64', 'int64', 'float32', 'int32'] \n",
                "                and df_basket[c].nunique() > 10]\n",
                "\n",
                "print(f'Binning {len(numeric_cols)} numeric features...')\n",
                "\n",
                "for col in numeric_cols:\n",
                "    # Engagement (Clicks)\n",
                "    if 'click' in col.lower():\n",
                "        bins = [-1, 0, 500, 2000, np.inf]\n",
                "        labels = [f'{col}_None', f'{col}_Low', f'{col}_Med', f'{col}_High']\n",
                "    # Submission Delays\n",
                "    elif 'delay' in col.lower():\n",
                "        bins = [-np.inf, -1, 0, 5, np.inf]\n",
                "        labels = [f'{col}_Early', f'{col}_OnTime', f'{col}_Slight', f'{col}_Late']\n",
                "    # Others (Quartiles)\n",
                "    else:\n",
                "        try:\n",
                "            binned = pd.qcut(df_basket[col], q=4, \n",
                "                           labels=[f'{col}_Q{i}' for i in range(1,5)], \n",
                "                           duplicates='drop')\n",
                "            df_basket = pd.concat([df_basket.drop(col, axis=1), pd.get_dummies(binned, dtype=bool)], axis=1)\n",
                "            continue\n",
                "        except:\n",
                "            median = df_basket[col].median()\n",
                "            binned = df_basket[col].apply(lambda x: f'{col}_Low' if x < median else f'{col}_High')\n",
                "    \n",
                "    try:\n",
                "        binned = pd.cut(df_basket[col], bins=bins, labels=labels)\n",
                "        df_basket = pd.concat([df_basket.drop(col, axis=1), pd.get_dummies(binned, dtype=bool)], axis=1)\n",
                "    except:\n",
                "        df_basket = df_basket.drop(col, axis=1)\n",
                "\n",
                "# Encode Target\n",
                "df_basket = pd.get_dummies(df_basket, columns=['final_result'], dtype=bool)\n",
                "df_basket = df_basket.astype(bool).fillna(False)\n",
                "\n",
                "print(f'‚úì Transaction basket ready: {df_basket.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run Apriori Algorithm (Full Dataset)\n",
                "\n",
                "We look for patterns with:\n",
                "- **Min Support: 5%** (Pattern must happen to >1,600 students)\n",
                "- **Min Confidence: 30%** (Rule must be correct >30% of the time)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "min_support = 0.05\n",
                "print(f'Running Apriori (min_support={min_support})...')\n",
                "\n",
                "frequent_itemsets = apriori(df_basket, min_support=min_support, \n",
                "                           use_colnames=True, verbose=1, low_memory=True)\n",
                "\n",
                "print(f'‚úì Found {len(frequent_itemsets):,} frequent itemsets')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Generate & Refine Rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "min_confidence = 0.3\n",
                "print(f'Generating rules (min_confidence={min_confidence})...')\n",
                "\n",
                "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
                "rules = rules[rules['lift'] > 1.0]  # Positive correlation only\n",
                "\n",
                "# 1. Filter for Dropout Outcomes\n",
                "def is_dropout(cons):\n",
                "    return any(x in str(cons) for x in ['final_result_Fail', 'final_result_Withdrawn'])\n",
                "\n",
                "dropout_rules = rules[rules['consequents'].apply(is_dropout)].copy()\n",
                "\n",
                "# 2. Deduplication (Keep \"Pure\" Dropout Rules)\n",
                "# We only want rules where the CONSEQUENT is just \"Withdrawn\" or \"Fail\"\n",
                "# Not \"Withdrawn + Low Clicks\"\n",
                "def is_pure_dropout(cons):\n",
                "    return len(cons) == 1 and ('final_result_Withdrawn' in list(cons)[0] or 'final_result_Fail' in list(cons)[0])\n",
                "\n",
                "dropout_rules = dropout_rules[dropout_rules['consequents'].apply(is_pure_dropout)].copy()\n",
                "dropout_rules = dropout_rules.sort_values('confidence', ascending=False)\n",
                "\n",
                "print(f'‚úì {len(dropout_rules):,} distinct dropout prediction rules')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Diversity Filtering\n",
                "Instead of showing 50 variations of \"Low Clicks + Education\", we group rules by **Feature Categories** to find truly distinct behavioral patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_feature_categories(antecedents):\n",
                "    \"\"\"Extract high-level feature categories from antecedent\"\"\"\n",
                "    cats = set()\n",
                "    for a in antecedents:\n",
                "        if 'click' in a.lower(): cats.add('Engagement')\n",
                "        elif 'education' in a.lower(): cats.add('Education')\n",
                "        elif 'delay' in a.lower(): cats.add('Timing')\n",
                "        elif 'late' in a.lower(): cats.add('Timing')\n",
                "        elif 'gender' in a.lower(): cats.add('Gender')\n",
                "        elif 'age' in a.lower(): cats.add('Age')\n",
                "        elif 'imd' in a.lower(): cats.add('Deprivation')\n",
                "        elif 'region' in a.lower(): cats.add('Region')\n",
                "        elif 'disability' in a.lower(): cats.add('Disability')\n",
                "    return cats\n",
                "\n",
                "# Select Top Diverse Rules\n",
                "selected_rules = []\n",
                "used_categories = []\n",
                "\n",
                "for idx, row in dropout_rules.iterrows():\n",
                "    cats = get_feature_categories(row['antecedents'])\n",
                "    \n",
                "    # Check for similarity with already selected rules\n",
                "    is_diverse = True\n",
                "    for used in used_categories:\n",
                "        # Jaccard similarity of categories\n",
                "        overlap = len(cats & used) / max(len(cats | used), 1)\n",
                "        if overlap > 0.6:  # If categories are >60% same, skip\n",
                "            is_diverse = False\n",
                "            break\n",
                "            \n",
                "    if is_diverse or len(selected_rules) < 3: # Always keep top 3 regardless\n",
                "        selected_rules.append(row)\n",
                "        used_categories.append(cats)\n",
                "        \n",
                "    if len(selected_rules) >= 8:\n",
                "        break\n",
                "\n",
                "diverse_df = pd.DataFrame(selected_rules)\n",
                "print(f'‚úì Selected {len(diverse_df)} DIVERSE patterns')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. üìñ Plain English Interpretation\n",
                "Translating technical rules into actionable insights with understandable metrics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_feature_name(name):\n",
                "    \"\"\"Translate variable names to plain English\"\"\"\n",
                "    mapping = {\n",
                "        'max_clicks_per_day_None': 'Zero Engagement',\n",
                "        'max_clicks_per_day_Low': 'Very Low Engagement',\n",
                "        'std_clicks_None': 'No Activity Variation',\n",
                "        'submit_delay_mean_Q2': 'Moderate Submission Delays',\n",
                "        'highest_education_Lower Than A Level': 'Lower Education Level',\n",
                "        'gender': 'Male Student',  # gender=1 is Male\n",
                "        'age_band_35-55': 'Older Student (35-55)',\n",
                "        'final_result_Withdrawn': 'Withdrawal',\n",
                "        'final_result_Fail': 'Failure'\n",
                "    }\n",
                "    if name in mapping: return mapping[name]\n",
                "    return name.replace('_', ' ').title()\n",
                "\n",
                "def print_rules_plain_english(rules_df, title):\n",
                "    print('\\n' + '='*80)\n",
                "    print(title)\n",
                "    print('='*80)\n",
                "\n",
                "    for i, (idx, row) in enumerate(rules_df.iterrows(), 1):\n",
                "        conditions = [clean_feature_name(x) for x in row['antecedents']]\n",
                "        outcome = clean_feature_name(list(row['consequents'])[0])\n",
                "        \n",
                "        print(f'\\nüìù RULE #{i}: {outcome} Risk Pattern')\n",
                "        print(f\"{'‚îÄ'*80}\")\n",
                "        print(f\"IF:   {' AND '.join(conditions)}\")\n",
                "        print(f\"THEN: Student will {outcome}\")\n",
                "        print(f\"\")\n",
                "        print(f\"üìä METRICS:\")\n",
                "        print(f\"   ‚Ä¢ Confidence: {row['confidence']:.1%} (probability this rule is correct)\")\n",
                "        print(f\"   ‚Ä¢ Lift:       {row['lift']:.2f}x   (how many times more likely vs random)\")\n",
                "        print(f\"   ‚Ä¢ Support:    {row['support']:.3f}   (proportion of students matching this)\")\n",
                "\n",
                "# 1. Top Diverse Rules\n",
                "print_rules_plain_english(diverse_df, 'TOP DIVERSE DROPOUT PATTERNS')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export Results\n",
                "diverse_df['rule_text'] = diverse_df.apply(lambda x: \n",
                "    f\"IF {', '.join([clean_feature_name(i) for i in x['antecedents']])} THEN {clean_feature_name(list(x['consequents'])[0])}\", axis=1)\n",
                "\n",
                "diverse_df[['rule_text', 'support', 'confidence', 'lift']].to_csv('../2_Outputs/final_dropout_rules_diverse.csv', index=False)\n",
                "print('\\n‚úì Saved plain English rules to: 2_Outputs/final_dropout_rules_diverse.csv')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Conclusion & Insights\n",
                "\n",
                "We identified **distinct behavioral phenotypes** that predict dropout:\n",
                "\n",
                "1. **Disengagement + Low Education**: The strongest predictor (**~6x risk**). Students with lower prior qualifications who fail to engage early are at critical risk.\n",
                "2. **Timing Indicators**: Even without knowing engagement depth, **submission delays** combined with **Male gender** or **Low education** are strong warnings.\n",
                "3. **Demographic Risks**: **Male students** and **Older students (35-55)** show specific vulnerability patterns when coupled with disengagement.\n",
                "\n",
                "**Intervention Strategy**:\n",
                "- **Immediate**: Automated flags for students with 0 clicks in Week 1.\n",
                "- **Targeted**: Extra support resources for students with lower prior qualifications.\n",
                "- **Monitoring**: Watch submission timing - delays are an early proxy for withdrawal."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}